<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Generative Visual Prompt: Unifying Distributional Control of Pre-Trained Generative Models">
  <meta name="keywords" content="Generative Models, Energy Based Models, Invertible Neural Networks">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Generative Visual Prompt: Unifying Distributional Control of Pre-Trained Generative Models</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-EQKV0ERPVV"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-EQKV0ERPVV');
</script>

<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">Generative Visual Prompt: Unifying Distributional Control of Pre-Trained Generative Models</h1>
          <div class="is-size-4 publication-authors">
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=en&user=WFKit_4AAAAJ&view_op=list_works&sortby=pubdate">Chen Henry Wu</a>,</span>
            <span class="author-block">
              <a href="https://scholar.google.ca/citations?user=lKZ7htMAAAAJ&hl=en">Saman Motamed</a>,</span>
            <span class="author-block">
              <a href="">Shaunak Srivastava</a>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=YB8_6gkAAAAJ&hl=en">Fernando De La Torre</a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Robotics Institute, Carnegie Mellon University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2209.06970.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2209.06970"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/ChenWu98/Generative-Visual-Prompt"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
               <!-- Colab Link. -->
              <span class="link-block">
                <a href="https://colab.research.google.com/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="--colab-logo-"></i>
                  </span>
                  <span>Colab coming soon!</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>




<section class="hero teaser">
    <div class="container is-max-desktop">
        <div class="hero-body">
            <img src="static/images/first_fig.jpg"
                                     alt="Teaser"/>
        </div>
    </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content">
          <p align="justify">
            Generative models (e.g., GANs and diffusion models) learn the underlying data distribution in an unsupervised manner. 
            However, many applications of interest require sampling from a particular region of the output space or sampling evenly over a range of characteristics. 
            For efficient sampling in these scenarios, we propose Generative Visual Prompt (PromptGen), a framework for distributional control over pre-trained generative models by incorporating knowledge of other off-the-shelf models. PromptGen defines control as energy-based models (EBMs) and samples images in a feed-forward manner by approximating the EBM with invertible neural networks, which avoids optimization at inference. 
            Our experiments show that PromptGen can efficiently sample from several unconditional generative models (e.g., StyleGAN2, StyleNeRF, diffusion autoencoder, NVAE) in a controlled or/and de-biased manner using various off-the-shelf models: 
            (1) with the CLIP model as control, PromptGen can sample images guided by text, (2) with image classifiers as control, PromptGen can help de-bias generative models across a set of attributes or attribute combinations, and (3) with inverse graphics models as control, PromptGen can sample images of the same identity in different poses. (4) Finally, PromptGen reveals that the CLIP model shows a "reporting bias" when used as control, and PromptGen can further de-bias this controlled distribution in an iterative manner.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <div style="align: left; text-align:center;">
        <!-- CLIP Guidance. -->
        <h2 class="title is-3">CLIP Guidance</h2>
        Given a pretrained CLIP model and a text description, PromptGen gives you a subspace of a pre-trained generator that matches the text decsription. 
        Below are a few examples using a StyleGAN model, trained on different datasets (Cat, FFHQ, etc)
    <br>
    <br>
          
          <figure>
            <img src="static/images/cat_closed_eyes_3r.jpg"
            <figcaption>text description: Photo of a cat with closed eyes</figcaption>
          </figure>
        <br>
          <figure>
            <img src="static/images/british_shorthair_first.jpg"
            <figcaption>text description: Photo of a British shorthair</figcaption>
        </figure>
  
        <br>
  
        <figure>
            <img src="static/images/happy_3r.jpg"
            <figcaption>text description: Photo of a happy person</figcaption>
        </figure>
  
      <br>
  <br>
  <br>
  <br>
  <!-- CLIP Guidance. -->
  
  <h2 class="title is-3">Pose Control</h2>
  <br>
  Using inverse graphics model DECA, PromptGen controls the pose of StyleGAN2 while preserving the identity.
  <br>
        <figure>
            <img src="static/images/inverse_graphics_pose_ffhq_resized.png"
        </figure>
  <br>
   <br>
   <br>
   <br>
  <h2 class="title is-3">De-biasing a Generator</h2> 
   <br>
    Biases in the data sneak into the generative models. For instance, a CLIP guided PromptGen using the sentence "Photo of a person witout makeup" will result
          in mostly females. To balance this undesired effect, PromptGen can use a classifier control and make the generator more fare with respect to gender.
     
          <br>
     <figure>
            <img src="static/images/promptgan_person_without_makeup_appendix.png"
                 <figcaption>text description: Photo of a person w/o makeup - pre-debiasing</figcaption>
     </figure>
      <br>
    <figure>
            <img src="static/images/gender_debias_lambda_2_promptgan_person_without_makeup_resized.png"
                 <figcaption>text description: Photo of a person w/o makeup - after-debiasing</figcaption>
     </figure>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{promptgen2022,
  title={Generative Visual Prompt: Unifying Distributional Control of Pre-Trained Generative Models},
  author={Chen Henry Wu and Saman Motamed and Shaunak Srivastava and Fernando De la Torre},
  booktitle={Thirty-Sixth Conference on Neural Information Processing Systems},
  year={2022},
  url={https://openreview.net/forum?id=Gsbnnc--bnw}
}</code></pre>
  </div>
</section>


<footer class="footer">
    <div class="container">
        <div class="content has-text-centered">
            <a class="icon-link"
               href="https://arxiv.org/abs/2209.06970">
                <i class="fas fa-file-pdf"></i>
            </a>
            <a class="icon-link" href="https://github.com/ChenWu98/Generative-Visual-Prompt" class="external-link" disabled>
                <i class="fab fa-github"></i>
            </a>
        </div>
        <div class="columns is-centered">
            <div class="column is-8">
                <div class="content">
                    <p>
                        This website is licensed under a <a rel="license"
                                                            href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                        Commons Attribution-ShareAlike 4.0 International License</a>.
                    </p>
                    <p>
                        This website's source code is based on the <a href="https://nerfies.github.io/"> Nerfies</a>
                        project page.
                        If you want to reuse their <a
                            href="https://github.com/nerfies/nerfies.github.io">source code</a>, please credit them
                        appropriately.
                    </p>
                </div>
            </div>
        </div>
    </div>
</footer>

</body>
</html>
