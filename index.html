<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Sam Motamed</title>
  
  <meta name="author" content="Sam Motamed">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ¤–</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
			<name>Sam Motamed</name>
              </p>
		
		    <p>I am an <a href="https://ellis.eu/projects/large-generative-vision-models-for-content-creation-and-representation-learning">ELLIS</a> Ph.D. student at <a href="https://insait.ai/">INSAIT</a> where I am advised by Prof. <a href="https://ee.ethz.ch/the-department/faculty/professors/person-detail.OTAyMzM=.TGlzdC80MTEsMTA1ODA0MjU5.html">Luc Van Gool</a> and a Student Researcher at Google DeepMind in Toronto.
              		
		    </p> 
              
              
		    <p>
                       Before that I was a visiting researcher from 2021 to 2023 at CMU's <a href="http://humansensing.cs.cmu.edu/home">Human Sensing Lab</a> working with the amazing <a href="https://www.cs.cmu.edu/~ftorre/">Fernando De La Torre</a>. I also spent 7 wonderful years at the University of Toronto's <a href="https://web.cs.toronto.edu/">Computer Science department</a> where I earned my HBSc and MS degrees.
              </p>
              <p style="text-align:center">
                <a href="mailto:saman.moatamed@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/resume_saman.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=lKZ7htMAAAAJ&hl=en&oi=ao">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/sammtmd">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/sam-motamed/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:80%">
              <a href="images/profile.jpeg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/profile.jpeg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm broadly interested in Generative Vision models for content creation, and currently focused on Video synthesis. My research aims to gain a better understanding of how to enable user-intuitive control over Generative models. I am also interested in bias mitigation and harnessing the power of large vision and language models by adapting them to solve personalized tasks using limited data. Relevant work is <span class="highlight">highlighted here</span>.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
					

		
		
		
	<heading>Publications</heading>

	<tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/d3gu-teaser.png" alt="fast-texture" width="240" height="240">
            </td>
            <td width="75%" valign="middle">
		    <a href="https://openaccess.thecvf.com/content/WACV2024/html/Zhang_D3GU_Multi-Target_Active_Domain_Adaptation_via_Enhancing_Domain_Alignment_WACV_2024_paper.html">
                <papertitle>D3GU: Multi-Target Active Domain Adaptation via Enhancing Domain Alignment </papertitle>
              </a>
              <br>
              Lin Zhang, Linghan Xu, <strong>Saman Motamed</strong>, Shayok Chakraborty, Fernando De la Torre
              <br>
              <em>WACV</em>, 2024
              <br>
		<a href="https://arxiv.org/abs/2401.05465">arxiv</a>
              <p>A Multi-Target Active Domain Adaptation (MT-ADA) framework for image classification.
              </p>
            </td>
          </tr>	


	<tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/parallel-teaser.png" alt="fast-texture" width="240" height="240">
            </td>
            <td width="75%" valign="middle">
		    <a href="https://openaccess.thecvf.com/content/WACV2024/html/Xu_Personalized_Face_Inpainting_With_Diffusion_Models_by_Parallel_Visual_Attention_WACV_2024_paper.html">
                <papertitle>Personalized Face Inpainting With Diffusion Models by Parallel Visual Attention </papertitle>
              </a>
              <br>
              Jianjin Xu, <strong>Saman Motamed</strong>, Praneetha Vaddamanu, Chen Henry Wu, Christian Haene, Jean-Charles Bazin, Fernando De la Torre
              <br>
              <em>WACV</em>, 2024
              <br>
		<a href="https://github.com/AtlantixJJ/PVA-CelebAHQ-IDI">code</a>&nbsp/&nbsp
		<a href="https://arxiv.org/abs/2312.03556">arxiv</a>
              <p>Fast, identity preserving face inpainting with diffusion models.
              </p>
            </td>
          </tr>	




		

	<tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/lego-teaser.png" alt="fast-texture" width="240" height="240">
            </td>
            <td width="75%" valign="middle">
		    <a href="https://sam-motamed.github.io/projects/lego">
                <papertitle>Lego: Learning to Disentangle and Invert Concepts Beyond Object Appearance in Text-to-Image Diffusion Models </papertitle>
              </a>
              <br>
              <strong>Saman Motamed</strong>, Danda Pani Paudel, Luc Van Gool
              <br>
              <em>arxiv</em>, 2023
              <br>
		<a href="https://github.com/sam-motamed/Lego">code</a>&nbsp/&nbsp
		<a href="https://arxiv.org/abs/2311.13833">arxiv</a>
              <p>A method for textual inversion of adjectives and verbs in text-to-image diffusion models.
              </p>
            </td>
          </tr>	




	
	<tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/patm.png" alt="fast-texture" width="240" height="220">
            </td>
            <td width="75%" valign="middle">
		    <a href="https://sam-motamed.github.io/projects/patmat">
                <papertitle>PATMAT: Person Aware Tuning of Mask-Aware Transformer for Face Inpainting </papertitle>
              </a>
              <br>
              <strong>Saman Motamed</strong>, Jianjin Xu, Chen Henry Wu, Fernando De la Torre
              <br>
              <em>ICCV</em>, 2023
              <br>
		    		<a href="https://openaccess.thecvf.com/content/ICCV2023/html/Motamed_PATMAT_Person_Aware_Tuning_of_Mask-Aware_Transformer_for_Face_Inpainting_ICCV_2023_paper.html">ICCV</a>&nbsp/&nbsp
		<a href="https://github.com/humansensinglab/PATMAT/tree/main">code</a>&nbsp/&nbsp
		<a href="https://arxiv.org/abs/2304.06107">arxiv</a>
              <p>A tuning method for personalizing inpainting of the face and preserving the odentity of a subject.
              </p>
            </td>
          </tr>	
		
		
		
		
		
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/promptgen.jpg" alt="fast-texture" width="240" height="240">
            </td>
            <td width="75%" valign="middle">
              <a href="https://chenwu98.github.io/PromptGen/">
                <papertitle>Generative Visual Prompt: Unifying Distributional Control of Pre-Trained Generative Models</papertitle>
              </a>
              <br>
              Chen Henry Wu, <strong>Saman Motamed</strong>, Shaunak Srivastava, Fernando De La Torre
              <br>
              <em>NeurIPS</em>, 2022
              <br>
		<a href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/8cb1c53863b290ee09b94d17f16ef355-Abstract-Conference.html">NeurIPS</a>&nbsp/&nbsp
              <a href="https://github.com/chenwu98/generative-visual-prompt">code</a>&nbsp/&nbsp
		<a href="https://arxiv.org/abs/2209.06970">arxiv</a>
              <p>A framework for defining control over latent-based generative models.
              </p>
            </td>
          </tr>
		
	</tbody></table>

	<br>
	<br>
	<br>
	<heading>Happenings</heading>
	<ul>
	<li> Oct 2023    Two papers accepted at WACV 2024. Details will be posted soon.
  	<li>Oct 2023 	I served as a volunteer at ICCV 23 and presented PATMAT.</li>
	</ul>

	      
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
		  <br>
		<br>
		<br>
		<br>
		<br>
		<br>
		<br>
		<br>
		<br>
		<br>
		<br>
		<br>
		<br>
		<br>
		<br>
		<br>
		<br>
		<br>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <center>Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a></center>
		    </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
		

</body>
     


</html>
